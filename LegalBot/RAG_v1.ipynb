{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from typing import Union, List\n",
    "\n",
    "from Database.Database_Weaviate import Database_Weaviate\n",
    "# from LLM.LLM_GGUF import LLM_GGUF as LLM\n",
    "from LLM.LLM_Ollama import LLM_Ollama as LLM\n",
    "\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG_Bot:\n",
    "    def __init__(self, collection_names=['Uk', 'Wales', 'NothernIreland', 'Scotland'], text_splitter='SpaCy', embedding_model=\"SentenceTransformers\"):\n",
    "        \"\"\"\n",
    "        Initializes the RAG_Bot object.\n",
    "        \n",
    "        Args:\n",
    "            collection_names (list, optional): A list of collection names. Defaults to ['Uk', 'Wales', 'NothernIreland', 'Scotland'].\n",
    "        \"\"\"\n",
    "        self.vector_db = Database_Weaviate(collection_names=collection_names, text_splitter=text_splitter, embedding_model=embedding_model)\n",
    "        self.llm = LLM()\n",
    "\n",
    "    def add_text(self, collection_name, text, metadata=None):\n",
    "        \"\"\"\n",
    "        Adds text data to a specified collection in the Weaviate database.\n",
    "        \n",
    "        Args:\n",
    "            collection_name (str): The name of the collection in the database.\n",
    "            text (str): The text data to be added.\n",
    "            metadata (dict): Additional metadata associated with the text.\n",
    "        \"\"\"\n",
    "        self.vector_db.vector_store = WeaviateVectorStore(\n",
    "            client=self.vector_db.client,\n",
    "            index_name=collection_name,\n",
    "            text_key=\"text\",\n",
    "            embedding=self.vector_db.embeddings,\n",
    "        )\n",
    "        \n",
    "        self.vector_db.add_text_to_db(\n",
    "            collection_name=collection_name,\n",
    "            text=text,\n",
    "            metadata=metadata\n",
    "        )\n",
    "\n",
    "    def __collection_routing(self, query) -> Union[str, List[str], None]:\n",
    "        \"\"\"\n",
    "        This function will route the query to the correct collection.\n",
    "        \n",
    "        Args:\n",
    "            query (str): The query to be routed.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, None]: The collection name or None if no collection matches the query.\n",
    "        \"\"\"\n",
    "\n",
    "        def check_for_existence_of_collection_names(query:str, collection_names:List[str]=['Uk', 'Wales', 'NothernIreland', 'Scotland']) -> Union[str, None]:\n",
    "            Existing_collection_names = []\n",
    "            for collection_name in collection_names:\n",
    "                if collection_name.lower() in query.lower():\n",
    "                    Existing_collection_names.append(collection_name)\n",
    "            if len(Existing_collection_names) > 0:\n",
    "                return Existing_collection_names\n",
    "            else:\n",
    "                return None\n",
    "            \n",
    "        mentioned_collections = check_for_existence_of_collection_names(query)\n",
    "        if mentioned_collections == None:\n",
    "            return None\n",
    "        elif mentioned_collections != None and mentioned_collections != [] and len(mentioned_collections) >= 1:\n",
    "            return mentioned_collections\n",
    "\n",
    "    def query(self, query:str, k:int=1, search_type='Hybrid', max_new_tokens=1000):\n",
    "        \"\"\"\n",
    "        Performs a RAG query on the specified collection using the Saul LLM\n",
    "\n",
    "        Args:\n",
    "            query (str): The query to search for similar documents.\n",
    "            k (int, optional): The number of documents to return. Defaults to 1.\n",
    "\n",
    "        Returns:\n",
    "            Response: The response from the LLM.\n",
    "        \"\"\"\n",
    "\n",
    "        Collection_to_query_from = self.__collection_routing(query)\n",
    "        print(f'Collection_to_query_from: {Collection_to_query_from}')\n",
    "\n",
    "        if not isinstance(Collection_to_query_from, list) and Collection_to_query_from == None:\n",
    "            print('There was no collection mentioned in the query. Kindly mention a collection name/s for the query to be executed.')\n",
    "\n",
    "        elif isinstance(Collection_to_query_from, list):\n",
    "            self.__query_all(query=query, k=k, collection_names=Collection_to_query_from, search_type=search_type, max_tokens=max_new_tokens)\n",
    "        \n",
    "    def __query_all(self, query, k=1, collection_names:List[str]=['Uk', 'Wales', 'Nothernireland', 'Scotland'], search_type='Hybrid', max_tokens=1000):\n",
    "        \"\"\"\n",
    "        Performs a RAG query on multiple specified collections using the Saul LLM.\n",
    "        \n",
    "        Args:\n",
    "            collection_name (str): The name of the collection in the database.\n",
    "            query (str): The query to search for similar documents.\n",
    "            k (int, optional): The number of documents to return. Defaults to 1.\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        \n",
    "        Prints the similarity score and the content of the top k documents that match the query.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Creating a WeaviateVectorStore for all counties one by one\n",
    "        for collection_name in collection_names:\n",
    "            #Validate existence of the collection itself first.\n",
    "            Validity = self.is_collection_empty(collection_name)\n",
    "            print(f'The Collection: {collection_name} is empty(0)/Not Empty(1): {Validity}')\n",
    "            \n",
    "            if not Validity:\n",
    "                if search_type == 'Vector':\n",
    "                    self.vector_db.vector_store = WeaviateVectorStore(\n",
    "                        client=self.vector_db.client,\n",
    "                        index_name=collection_name,\n",
    "                        text_key=\"text\",\n",
    "                        embedding=self.vector_db.embeddings,\n",
    "                    )\n",
    "                \n",
    "                    # Get the current WeaviateVectorStore\n",
    "                    current_db = self.vector_db.vector_store\n",
    "                    \n",
    "                    # Create a retriever for the current database\n",
    "                    retriever = current_db.as_retriever(\n",
    "                        search_kwargs={\"k\": k})\n",
    "\n",
    "                    # Function to format documents into a single context string\n",
    "                    def format_docs(docs):\n",
    "                        print(f'The retrieved documents are:')\n",
    "                        for idx,doc in enumerate(docs):\n",
    "                            print(f'{idx} - Content: {doc.page_content[:50]}... - MetaData: {doc.metadata}')\n",
    "                        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "                    \n",
    "                    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "                    context = format_docs(retrieved_docs)\n",
    "                    \n",
    "                    response = self.llm.chat(context={context},\n",
    "                                            query={query},\n",
    "                                            max_new_tokens=max_tokens)\n",
    "                    print(f'\\n\\nThe response is from the collection: {collection_name}\\n')\n",
    "                    for chunk in response:\n",
    "                        print(chunk, end='', flush=True)\n",
    "                    print(f'\\nThe response has been generated above ^\\n\\n')\n",
    "\n",
    "                elif search_type == 'Hybrid':\n",
    "                    current_collection = self.vector_db.client.collections.get(collection_name)\n",
    "                    responses = current_collection.query.hybrid(query=query,\n",
    "                                                                vector=self.vector_db.embeddings.embed_query(query),\n",
    "                                                                limit=k)\n",
    "                    Text_Docs = []\n",
    "                    Text_Meta_Datas = []\n",
    "                    \n",
    "                    for o in responses.objects: #output docs of the hybrid search\n",
    "                        Text_Docs.append(o.properties['text'])\n",
    "                        Text_Meta_Datas.append({k: v for k, v in o.properties.items() if k != 'text'})\n",
    "\n",
    "                    def format_docs(docs):\n",
    "                        print(f'The retrieved documents are:')\n",
    "                        for idx,(doc,meta) in enumerate(zip(docs,Text_Meta_Datas)):\n",
    "                            print(f'{idx} - Content: {doc[:50]}... - MetaData: {meta}')\n",
    "                        return \"\\n\\n\".join(doc for doc in docs)\n",
    "\n",
    "                    concat_docs = format_docs(Text_Docs)\n",
    "\n",
    "                    response = self.llm.chat(context={concat_docs},\n",
    "                                            query={query},\n",
    "                                            max_new_tokens=max_tokens)\n",
    "                    print(f'\\n\\nThe response is from the collection: {collection_name}\\n')\n",
    "                    for chunk in response:\n",
    "                        print(chunk, end='', flush=True)\n",
    "                    print(f'\\nThe response has been generated above ^\\n\\n')\n",
    "                    \n",
    "    def is_collection_empty(self, collection_name: str) -> bool:\n",
    "        current_client = self.vector_db.client.collections.get(collection_name)\n",
    "        for doc in current_client.iterator():\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def get_list_of_all_docs(self, collection_name:Union[str, List[str]]=None) -> None:\n",
    "        \"\"\"\n",
    "        Function to get the list of all documents in the specified collection.\n",
    "        \n",
    "        Args:\n",
    "            collection_name (Union[str, List[str]], optional): The name of the collection in the database. Defaults to None.\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if isinstance(collection_name, list):\n",
    "            for collection in collection_name:\n",
    "                is_empty = self.is_collection_empty(collection)\n",
    "                if not is_empty:\n",
    "                    self.get_list_of_all_docs(collection)\n",
    "\n",
    "        elif isinstance(collection_name, str):\n",
    "            collection_existence_validity = self.is_collection_empty(collection_name)\n",
    "            if not collection_existence_validity:\n",
    "                print(f'The collection {collection_name} has the following documents:')\n",
    "                current_client = self.vector_db.client.collections.get(collection_name)\n",
    "                for item in current_client.iterator():\n",
    "                    for idxKey,Key in enumerate(item.properties.keys()):\n",
    "                        print(f'{Key}:  {item.properties[Key]}')\n",
    "                print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster_URL: https://gwqaighsqp6gtrk8kwmnmg.c0.us-west3.gcp.weaviate.cloud, Cluster_API: 2xKmTTGUawzXYItFrMR9JgTjY2oRkfzHFLWN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724084658.145401  157996 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 4 Weaviate Clusters - Option 3\n",
      "Country.capitalize(): Uk\n",
      "The collection: Uk already exists in the Weaviate Cluster\n",
      "Country.capitalize(): Wales\n",
      "The collection: Wales already exists in the Weaviate Cluster\n",
      "Country.capitalize(): Nothernireland\n",
      "The collection: NothernIreland already exists in the Weaviate Cluster\n",
      "Country.capitalize(): Scotland\n",
      "The collection: Scotland already exists in the Weaviate Cluster\n"
     ]
    }
   ],
   "source": [
    "collection_names = ['Uk', 'Wales', 'NothernIreland', 'Scotland']\n",
    "bot = RAG_Bot(collection_names=collection_names, text_splitter='SpaCy', embedding_model=\"SentenceTransformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bot.vector_db.delete_all_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Collection Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To mention the countries, write any country name in the following manner:\n",
    "- Uk\n",
    "- Wales\n",
    "- Scotland\n",
    "- NothernIreland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection_to_query_from: ['NothernIreland']\n",
      "The Collection: NothernIreland is empty(0)/Not Empty(1): False\n",
      "The retrieved documents are:\n",
      "0 - Content: STATUTORY INSTRUMENTS\n",
      "2022\n",
      "\n",
      "No. 1145\n",
      "TERMS AND CON... - MetaData: {'title': 'The Exclusivity Terms for Zero Hours Workers (Unenforceability and Redress) Regulations 2022.txt', 'legislation': 'UK Statutory Instruments', 'legislationType': 'May contain legislation that applies to NothernIreland', 'year': '2022', 'country': 'NothernIreland'}\n",
      "1 - Content: The Secretary of State must from time to timeâ€”\n",
      "(a)... - MetaData: {'legislationType': 'May contain legislation that applies to NothernIreland', 'legislation': 'UK Draft Statutory Instruments', 'year': '2022', 'title': 'The Exclusivity Terms for Zero Hours Workers (Unenforceability and Redress) Regulations 2022\\nSuperseded by 2022 No. 1145.txt', 'country': 'NothernIreland'}\n",
      "2 - Content: Draft Regulations laid before Parliament under sec... - MetaData: {'title': 'The Exclusivity Terms for Zero Hours Workers (Unenforceability and Redress) Regulations 2022\\nSuperseded by 2022 No. 1145.txt', 'legislation': 'UK Draft Statutory Instruments', 'legislationType': 'May contain legislation that applies to NothernIreland', 'year': '2022', 'country': 'NothernIreland'}\n",
      "\n",
      "\n",
      "The response is from the collection: NothernIreland\n",
      "Generated Response\n",
      "Based on the provided document, which is related to English and Welsh law, I must inform you that it does not cover Northern Ireland. The document explicitly states that the Regulations extend to \"England and Wales and Scotland\", but does not mention Northern Ireland.\n",
      "\n",
      "However, as a general legal expert, I can tell you that labor laws in Northern Ireland are governed by separate legislation, such as the Employment Rights (Northern Ireland) Order 1996 and related regulations.\n",
      "\n",
      "If you need specific information on labor laws and limitations within Northern Ireland, I recommend consulting the relevant authorities or resources that specialize in Northern Irish law.The response has been generated above ^\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bot.query(query='Define labor laws and limitations within NothernIreland?', k=3, search_type='Hybrid') #or Vector with a Capital V #change the query here with your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.query(query='Define labor laws and limitations within Wales?', k=2, search_type='Vector') #or Vector with a Capital V #change the query here with your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.query(query='what does wales have?', k=2, search_type='Vector') #change the query here with your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.query(query='scotty from scotland uk/', k=1) #change the query here with your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.query(query='scotty from scotland USA', k=1) #change the query here with your text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
