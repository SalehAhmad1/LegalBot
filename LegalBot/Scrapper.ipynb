{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import All the Required Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_target_year_existence(driver, url, legislation_name, year):\n",
    "    target_url_year = f'{url}/{year}'\n",
    "    try:\n",
    "        driver.get(target_url_year)\n",
    "        return True\n",
    "    except:\n",
    "        print(f'Exception: The legislation:{legislation_name} does not have any titles for the year: {year}')\n",
    "        return False\n",
    "    \n",
    "def fetch_leg_types(driver, div_selector):\n",
    "    div_element = driver.find_element(By.CSS_SELECTOR, div_selector)\n",
    "    leg_types_elements = div_element.find_elements(By.CSS_SELECTOR, 'ul.legTypes')\n",
    "\n",
    "    if leg_types_elements:\n",
    "        leg_types_element = leg_types_elements[0]\n",
    "        list_items = leg_types_element.find_elements(By.TAG_NAME, 'li')\n",
    "        list_names = [item.text for item in list_items]\n",
    "        list_hrefs = [item.find_element(By.TAG_NAME, 'a').get_attribute('href') for item in list_items if item.find_element(By.TAG_NAME, 'a')]\n",
    "        return dict(zip(list_names, list_hrefs))\n",
    "    else:\n",
    "        return [], []\n",
    "    \n",
    "def get_legislations_href(driver, country, country_home_url):\n",
    "    driver.get(country_home_url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    selectors = ['div.s_4.p_one.legCol', 'div.s_4.p_two.legCol']\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_selector = {executor.submit(fetch_leg_types, driver, selector): selector for selector in selectors}\n",
    "        results = []\n",
    "\n",
    "        for future in as_completed(future_to_selector):\n",
    "            selector = future_to_selector[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                results.append(data)\n",
    "            except Exception as exc:\n",
    "                print(f'Error fetching data for {selector}: {exc}')\n",
    "\n",
    "    Final_Results = {\n",
    "        f'Exclusively or primarily applies to {country}': results[0],\n",
    "        f'May contain legislation that applies to {country}': results[1]\n",
    "    } \n",
    "    return Final_Results\n",
    "\n",
    "def filter_keys(data):\n",
    "    filtered_data = {}\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, dict):\n",
    "            filtered_data[key] = {k: v for k, v in value.items() if k.startswith(\"Exclusively\")}\n",
    "    return filtered_data\n",
    "\n",
    "def get_final_target_legislations(All_Legislations, Each_Countries_Uniques, Each_Countries_Overlaps):\n",
    "    Each_Countries_Uniques_updated_keys = []\n",
    "    Each_Countries_Uniques_updated_values = []\n",
    "    for x in Each_Countries_Uniques:\n",
    "        Each_Countries_Uniques_updated_keys.append(list(x.keys()))\n",
    "        Each_Countries_Uniques_updated_values.append(list(x.values()))\n",
    "        \n",
    "    Each_Countries_Overlaps_updated_keys = []\n",
    "    Each_Countries_Overlaps_updated_values = []\n",
    "    for x in Each_Countries_Overlaps:\n",
    "        Each_Countries_Overlaps_updated_keys.append(list(x.keys()))\n",
    "        Each_Countries_Overlaps_updated_values.append(list(x.values()))\n",
    "    \n",
    "    Overlaps_not_in_any_unique = []\n",
    "    for country, overlap in  zip(['UK', 'Scotland', 'Wales', 'ni'],Each_Countries_Overlaps_updated_keys):\n",
    "        # print(f'Country: {country}')\n",
    "        for ovl in overlap: #overlap of current country\n",
    "            check = False\n",
    "            for country_other, uniques in zip(['UK', 'Scotland', 'Wales', 'ni'],Each_Countries_Uniques_updated_keys):\n",
    "                if country_other == country:\n",
    "                    continue\n",
    "                else:\n",
    "                    if ovl in uniques:\n",
    "                        check = True\n",
    "            if check == False:\n",
    "                Overlaps_not_in_any_unique.append(ovl)\n",
    "                # print(f'Overlap: -{ovl}- not in any countries uniques')\n",
    "    Unique_Overlaps = np.unique(Overlaps_not_in_any_unique)\n",
    "\n",
    "    idx = 0\n",
    "    hrefs_dict_of_unique_overlaps = {}\n",
    "    for country in Each_Countries_Overlaps:\n",
    "        for key, val in country.items():\n",
    "            if key in Unique_Overlaps:\n",
    "                hrefs_dict_of_unique_overlaps[key] = val\n",
    "    hrefs_dict_of_unique_overlaps\n",
    "    \n",
    "    All_Legislations = filter_keys(All_Legislations)\n",
    "    All_Legislations['Extras'] = {'Legislations that are unique to none': hrefs_dict_of_unique_overlaps}\n",
    "\n",
    "    # for key, val in All_Legislations.items():\n",
    "    #     print(f'{key}:\\n {val}\\n')\n",
    "        \n",
    "    return All_Legislations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "> Get All Legislations\n",
    "> - Legislations Unique to a Country\n",
    "> - Legislations not Unique to any Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Legislations = {}\n",
    "Each_Countries_Uniques = []\n",
    "Each_Countries_Overlaps = []\n",
    "\n",
    "for idxCountry, Country in enumerate(['UK', 'Scotland', 'Wales', 'ni']):\n",
    "    Country_Name = Country\n",
    "    if Country_Name == 'ni':\n",
    "        Country_Name = 'NothernIreland'\n",
    "    Country_URL = os.path.join('https://www.legislation.gov.uk/browse' , Country.lower())\n",
    "    \n",
    "    print(f'Getting Legislations HREFs for the country: {Country_Name}')\n",
    "    \n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "    driver.get(Country_URL)\n",
    "    time.sleep(2)\n",
    "\n",
    "    Country_Legislations = get_legislations_href(driver=driver,\n",
    "                                                country=f'{Country_Name}',\n",
    "                                                country_home_url=f'{Country_URL}')\n",
    "    \n",
    "    All_Legislations[Country_Name] = Country_Legislations\n",
    "    \n",
    "    Each_Countries_Uniques.append(Country_Legislations[list(Country_Legislations.keys())[0]])\n",
    "    Each_Countries_Overlaps.append(Country_Legislations[list(Country_Legislations.keys())[1]])\n",
    "    \n",
    "Final_Legislations = get_final_target_legislations(All_Legislations, Each_Countries_Uniques, Each_Countries_Overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Legislations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Legislations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> Given all legislations and target years, extract titles and then content of each title and save to a .txt file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Scrape Content from the Legislations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_url_existence(driver, url): #the url is year url\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(1)\n",
    "        content_div = driver.find_element(By.CSS_SELECTOR, 'div.results') #if there are titles. that year has titles\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def extract_content(driver, title_url):\n",
    "    driver.get(title_url)\n",
    "    time.sleep(1)\n",
    "    Title_Content_Div = driver.find_element(By.CSS_SELECTOR, 'div.legToc')\n",
    "    NavBar = Title_Content_Div.find_element(By.ID, 'legSubNav')\n",
    "    NavBarLists = NavBar.find_elements(By.TAG_NAME, 'li')\n",
    "    ContentTab = NavBarLists[1]\n",
    "    Content_Link = ContentTab.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "    \n",
    "    driver.get(Content_Link)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    '''Now get the content'''\n",
    "    '''Multiple Pages of the content page'''\n",
    "    Page_Number = 1\n",
    "    All_Provisions_Text = ''\n",
    "    while True:\n",
    "        Content_Box = driver.find_element(By.ID, 'content')\n",
    "        Content_Text = Content_Box.find_element(By.ID, 'viewLegContents').find_element(By.CLASS_NAME, 'LegSnippet')\n",
    "        page_Text = Content_Text.text\n",
    "        All_Provisions_Text += page_Text\n",
    "        print(f'Page Number: {Page_Number}')\n",
    "        # print(f'Page Text: {page_Text}')\n",
    "        \n",
    "        '''Now check for button'''\n",
    "        Button_Panel = driver.find_element(By.CLASS_NAME, 'prevNextNav')\n",
    "        try:\n",
    "            Next_Button = Button_Panel.find_element(By.TAG_NAME, 'ul').find_elements(By.TAG_NAME, 'li')[-1].find_element(By.TAG_NAME, 'a')\n",
    "            print(f'Next Button found: {Next_Button.text}')\n",
    "            try:\n",
    "                Next_Button.click()\n",
    "                time.sleep(1)\n",
    "                Page_Number += 1\n",
    "            except:\n",
    "                print(f'You are probably on the very last Provision page')\n",
    "                print(f'Provision Page Number: {Page_Number}')\n",
    "                break\n",
    "        except:\n",
    "            print(f'No Next Button Found - Last Provision Page')\n",
    "            print(f'Provision Page Number: {Page_Number}')\n",
    "            break\n",
    "    return All_Provisions_Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles_names_hrefs(driver, country, legislation_name, legislation_url, target_year):\n",
    "    All_Titles = {}\n",
    "\n",
    "    driver.get(legislation_url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    Target_Years = [target_year]\n",
    "    for idxYear, year in enumerate(Target_Years):\n",
    "        Target_Year_Legislation_URL = f'{legislation_url}/{year}'\n",
    "        check_target_year_existence = verify_url_existence(driver, Target_Year_Legislation_URL)\n",
    "            \n",
    "        if check_target_year_existence == False:\n",
    "            print(f'For the legislation: {legislation_name} does not have any titles for the year: {year}')\n",
    "        else:\n",
    "            Title_Names = []\n",
    "            Title_HREFs = []\n",
    "            num = 1\n",
    "            while True:\n",
    "                content_div = driver.find_element(By.CSS_SELECTOR, 'div.results')\n",
    "                table = content_div.find_element(By.TAG_NAME, 'table')\n",
    "                tbody = table.find_element(By.TAG_NAME, 'tbody')\n",
    "                tr_elements = tbody.find_elements(By.TAG_NAME, 'tr')\n",
    "                for tr in tr_elements: #Iterate over the table rows / titles\n",
    "                    first_td = tr.find_element(By.TAG_NAME, 'td')\n",
    "                    name = first_td.text\n",
    "                    href = first_td.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                    Title_Names.append(name)\n",
    "                    Title_HREFs.append(href)\n",
    "                    \n",
    "                footer = driver.find_element(By.CSS_SELECTOR, 'div.contentFooter')\n",
    "                ContentFooter = footer.find_element(By.CLASS_NAME, 'interface')\n",
    "                ContentFooterInterface = ContentFooter.find_element(By.CSS_SELECTOR, 'div.prevPagesNextNav')\n",
    "                List = ContentFooterInterface.find_element(By.TAG_NAME, 'ul')\n",
    "                Lists = List.find_elements(By.TAG_NAME, 'li')\n",
    "                \n",
    "                Next_Button_Found = False\n",
    "                LastButton = None\n",
    "                try:\n",
    "                    LastButton = Lists[-1].find_element(By.TAG_NAME, 'a')\n",
    "                    if 'Next' in LastButton.text:\n",
    "                        # print(f'Next Button found: {LastButton.text}')\n",
    "                        Next_Button_Found = True\n",
    "                except:\n",
    "                    # print(f'No Next Button Found - Last Page')\n",
    "                    All_Titles[year] = dict(zip(Title_Names, Title_HREFs))\n",
    "                    break\n",
    "                \n",
    "                if Next_Button_Found == True:\n",
    "                    num += 1\n",
    "                    # print(f'Page: {num}')\n",
    "                    LastButton.click()\n",
    "                    time.sleep(2)\n",
    "    return All_Titles\n",
    "\n",
    "def create_dirs(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "for idxCountry, (Country_Key, Country_Value_Dict) in enumerate(All_Legislations.items()): #or Final_Legislations\n",
    "    for data_key, data_value in Country_Value_Dict.items(): #Iterates for 1 time. i.e. the only type of legislation in it\n",
    "        for legislation_name, legislation_href in data_value.items():\n",
    "            for idxYear, year in enumerate(['2024']):\n",
    "                '''The variable below will have titles for all the target years of the loop of that legislation'''\n",
    "                print(f'Country: {Country_Key} - {data_key} - {legislation_name} - {year}')\n",
    "                All_Titles = get_titles_names_hrefs(driver=driver, country=Country_Key, legislation_name=legislation_name, legislation_url=legislation_href, target_year=year)\n",
    "                if f'{year}' in All_Titles:\n",
    "                    print(len(All_Titles[year]))\n",
    "                    print(All_Titles[year])\n",
    "                    print()\n",
    "                    print(f'---', end='\\n')\n",
    "                \n",
    "                for title_name, title_href in All_Titles[year].items(): \n",
    "                    print(f'{title_name} - {title_href}')\n",
    "                    title_content = extract_content(driver=driver, title_url=title_href)\n",
    "                    \n",
    "                    create_dirs(path=f'./Scraped_Content/{Country_Key}/{data_key}/{legislation_name}/{year}')\n",
    "                    with open(f'./Scraped_Content/{Country_Key}/{data_key}/{legislation_name}/{year}/{title_name}.txt', 'w') as f:\n",
    "                        f.write(title_content)\n",
    "                #     break\n",
    "    #             break\n",
    "    #         break\n",
    "    #     break\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
