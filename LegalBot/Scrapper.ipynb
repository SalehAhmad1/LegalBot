{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import All the Required Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_target_year_existence(driver, url, legislation_name, year):\n",
    "    target_url_year = f'{url}/{year}'\n",
    "    try:\n",
    "        driver.get(target_url_year)\n",
    "        return True\n",
    "    except:\n",
    "        print(f'Exception: The legislation:{legislation_name} does not have any titles for the year: {year}')\n",
    "        return False\n",
    "    \n",
    "def fetch_leg_types(driver, div_selector):\n",
    "    div_element = driver.find_element(By.CSS_SELECTOR, div_selector)\n",
    "    leg_types_elements = div_element.find_elements(By.CSS_SELECTOR, 'ul.legTypes')\n",
    "\n",
    "    if leg_types_elements:\n",
    "        leg_types_element = leg_types_elements[0]\n",
    "        list_items = leg_types_element.find_elements(By.TAG_NAME, 'li')\n",
    "        list_names = [item.text for item in list_items]\n",
    "        list_hrefs = [item.find_element(By.TAG_NAME, 'a').get_attribute('href') for item in list_items if item.find_element(By.TAG_NAME, 'a')]\n",
    "        return dict(zip(list_names, list_hrefs))\n",
    "    else:\n",
    "        return [], []\n",
    "    \n",
    "def get_legislations_href(driver, country, country_home_url):\n",
    "    driver.get(country_home_url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    selectors = ['div.s_4.p_one.legCol', 'div.s_4.p_two.legCol']\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_selector = {executor.submit(fetch_leg_types, driver, selector): selector for selector in selectors}\n",
    "        results = []\n",
    "\n",
    "        for future in as_completed(future_to_selector):\n",
    "            selector = future_to_selector[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                results.append(data)\n",
    "            except Exception as exc:\n",
    "                print(f'Error fetching data for {selector}: {exc}')\n",
    "\n",
    "    Final_Results = {\n",
    "        f'Exclusively or primarily applies to {country}': results[0],\n",
    "        f'May contain legislation that applies to {country}': results[1]\n",
    "    } \n",
    "    return Final_Results\n",
    "\n",
    "def filter_keys(data):\n",
    "    filtered_data = {}\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, dict):\n",
    "            filtered_data[key] = {k: v for k, v in value.items() if k.startswith(\"Exclusively\")}\n",
    "    return filtered_data\n",
    "\n",
    "def get_final_target_legislations(All_Legislations, Each_Countries_Uniques, Each_Countries_Overlaps):\n",
    "    Each_Countries_Uniques_updated_keys = []\n",
    "    Each_Countries_Uniques_updated_values = []\n",
    "    for x in Each_Countries_Uniques:\n",
    "        Each_Countries_Uniques_updated_keys.append(list(x.keys()))\n",
    "        Each_Countries_Uniques_updated_values.append(list(x.values()))\n",
    "        \n",
    "    Each_Countries_Overlaps_updated_keys = []\n",
    "    Each_Countries_Overlaps_updated_values = []\n",
    "    for x in Each_Countries_Overlaps:\n",
    "        Each_Countries_Overlaps_updated_keys.append(list(x.keys()))\n",
    "        Each_Countries_Overlaps_updated_values.append(list(x.values()))\n",
    "    \n",
    "    Overlaps_not_in_any_unique = []\n",
    "    for country, overlap in  zip(['UK', 'Scotland', 'Wales', 'ni'],Each_Countries_Overlaps_updated_keys):\n",
    "        # print(f'Country: {country}')\n",
    "        for ovl in overlap: #overlap of current country\n",
    "            check = False\n",
    "            for country_other, uniques in zip(['UK', 'Scotland', 'Wales', 'ni'],Each_Countries_Uniques_updated_keys):\n",
    "                if country_other == country:\n",
    "                    continue\n",
    "                else:\n",
    "                    if ovl in uniques:\n",
    "                        check = True\n",
    "            if check == False:\n",
    "                Overlaps_not_in_any_unique.append(ovl)\n",
    "                # print(f'Overlap: -{ovl}- not in any countries uniques')\n",
    "    Unique_Overlaps = np.unique(Overlaps_not_in_any_unique)\n",
    "\n",
    "    idx = 0\n",
    "    hrefs_dict_of_unique_overlaps = {}\n",
    "    for country in Each_Countries_Overlaps:\n",
    "        for key, val in country.items():\n",
    "            if key in Unique_Overlaps:\n",
    "                hrefs_dict_of_unique_overlaps[key] = val\n",
    "    hrefs_dict_of_unique_overlaps\n",
    "    \n",
    "    All_Legislations = filter_keys(All_Legislations)\n",
    "    All_Legislations['Extras'] = {'Legislations that are unique to none': hrefs_dict_of_unique_overlaps}\n",
    "\n",
    "    # for key, val in All_Legislations.items():\n",
    "    #     print(f'{key}:\\n {val}\\n')\n",
    "        \n",
    "    return All_Legislations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "> Get All Legislations\n",
    "> - Legislations Unique to a Country\n",
    "> - Legislations not Unique to any Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Legislations = {}\n",
    "Each_Countries_Uniques = []\n",
    "Each_Countries_Overlaps = []\n",
    "\n",
    "for idxCountry, Country in enumerate(['UK', 'Scotland', 'Wales', 'ni']):\n",
    "    Country_Name = Country\n",
    "    if Country_Name == 'ni':\n",
    "        Country_Name = 'NothernIreland'\n",
    "    Country_URL = os.path.join('https://www.legislation.gov.uk/browse' , Country.lower())\n",
    "    \n",
    "    print(f'Getting Legislations HREFs for the country: {Country_Name}')\n",
    "    \n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "    driver.get(Country_URL)\n",
    "    time.sleep(2)\n",
    "\n",
    "    Country_Legislations = get_legislations_href(driver=driver,\n",
    "                                                country=f'{Country_Name}',\n",
    "                                                country_home_url=f'{Country_URL}')\n",
    "    \n",
    "    All_Legislations[Country_Name] = Country_Legislations\n",
    "    \n",
    "    Each_Countries_Uniques.append(Country_Legislations[list(Country_Legislations.keys())[0]])\n",
    "    Each_Countries_Overlaps.append(Country_Legislations[list(Country_Legislations.keys())[1]])\n",
    "    \n",
    "Final_Legislations = get_final_target_legislations(All_Legislations, Each_Countries_Uniques, Each_Countries_Overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UK': {'Exclusively or primarily applies to UK': {'UK Public General Acts': 'https://www.legislation.gov.uk/ukpga',\n",
       "   'UK Local Acts': 'https://www.legislation.gov.uk/ukla',\n",
       "   'UK Private and Personal Acts': 'https://www.legislation.gov.uk/ukppa',\n",
       "   'UK Statutory Instruments': 'https://www.legislation.gov.uk/uksi',\n",
       "   'UK Ministerial Directions': 'https://www.legislation.gov.uk/ukmd',\n",
       "   'UK Ministerial Orders': 'https://www.legislation.gov.uk/ukmo',\n",
       "   'UK Statutory Rules and Orders 1900-1948': 'https://www.legislation.gov.uk/uksro',\n",
       "   'UK Draft Statutory Instruments': 'https://www.legislation.gov.uk/ukdsi'}},\n",
       " 'Scotland': {'Exclusively or primarily applies to Scotland': {'Acts of the Scottish Parliament': 'https://www.legislation.gov.uk/asp',\n",
       "   'Acts of the Old Scottish Parliament 1424-1707': 'https://www.legislation.gov.uk/aosp',\n",
       "   'Scottish Statutory Instruments': 'https://www.legislation.gov.uk/ssi',\n",
       "   'Scottish Draft Statutory Instruments': 'https://www.legislation.gov.uk/sdsi'}},\n",
       " 'Wales': {'Exclusively or primarily applies to Wales': {'Acts of Senedd Cymru': 'https://www.legislation.gov.uk/asc',\n",
       "   'Wales Statutory Instruments': 'https://www.legislation.gov.uk/wsi',\n",
       "   'Acts of the National Assembly for Wales': 'https://www.legislation.gov.uk/anaw',\n",
       "   'Measures of the National Assembly for Wales': 'https://www.legislation.gov.uk/mwa'}},\n",
       " 'NothernIreland': {'Exclusively or primarily applies to NothernIreland': {'Acts of the Northern Ireland Assembly': 'https://www.legislation.gov.uk/nia',\n",
       "   'Acts of the Old Irish Parliament 1495-1800': 'https://www.legislation.gov.uk/aip',\n",
       "   'Northern Ireland Statutory Rules': 'https://www.legislation.gov.uk/nisr',\n",
       "   'Northern Ireland Orders in Council': 'https://www.legislation.gov.uk/nisi',\n",
       "   'Northern Ireland Assembly Measures 1974': 'https://www.legislation.gov.uk/mnia',\n",
       "   'Acts of the Northern Ireland Parliament 1921-1972': 'https://www.legislation.gov.uk/apni',\n",
       "   'Northern Ireland Statutory Rules and Orders 1922-1973': 'https://www.legislation.gov.uk/nisro',\n",
       "   'Northern Ireland Draft Statutory Rules': 'https://www.legislation.gov.uk/nidsr'}},\n",
       " 'Extras': {'Legislations that are unique to none': {'Acts of the English Parliament 1267-1706': 'https://www.legislation.gov.uk/aep',\n",
       "   'Acts of the Parliament of Great Britain 1707-1800': 'https://www.legislation.gov.uk/apgb',\n",
       "   'Local Acts of the Parliament of Great Britain 1797-1800': 'https://www.legislation.gov.uk/gbla',\n",
       "   'Private and Personal Acts of the Parliament of Great Britain 1707-1800': 'https://www.legislation.gov.uk/gbppa',\n",
       "   'UK Church Measures': 'https://www.legislation.gov.uk/ukcm',\n",
       "   'Church Instruments': 'https://www.legislation.gov.uk/ukci'}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Legislations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Scrape Content from the Legislations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/SalehAhmad1/mem0.git@937d9b3f1bfffddcda86ea4a337608d0cd9372fa\n",
      "  Cloning https://github.com/SalehAhmad1/mem0.git (to revision 937d9b3f1bfffddcda86ea4a337608d0cd9372fa) to /tmp/pip-req-build-q5rf3btt\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/SalehAhmad1/mem0.git /tmp/pip-req-build-q5rf3btt\n",
      "  Running command git rev-parse -q --verify 'sha^937d9b3f1bfffddcda86ea4a337608d0cd9372fa'\n",
      "  Running command git fetch -q https://github.com/SalehAhmad1/mem0.git 937d9b3f1bfffddcda86ea4a337608d0cd9372fa\n",
      "  Resolved https://github.com/SalehAhmad1/mem0.git to commit 937d9b3f1bfffddcda86ea4a337608d0cd9372fa\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: openai<2.0.0,>=1.33.0 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from mem0ai==0.0.2) (1.35.10)\n",
      "Requirement already satisfied: posthog<4.0.0,>=3.5.0 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from mem0ai==0.0.2) (3.5.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.3 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from mem0ai==0.0.2) (2.8.2)\n",
      "Requirement already satisfied: qdrant-client<2.0.0,>=1.9.1 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from mem0ai==0.0.2) (1.10.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from posthog<4.0.0,>=3.5.0->mem0ai==0.0.2) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from posthog<4.0.0,>=3.5.0->mem0ai==0.0.2) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from posthog<4.0.0,>=3.5.0->mem0ai==0.0.2) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from posthog<4.0.0,>=3.5.0->mem0ai==0.0.2) (1.11.1)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from posthog<4.0.0,>=3.5.0->mem0ai==0.0.2) (2.9.0.post0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.3->mem0ai==0.0.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.3->mem0ai==0.0.2) (2.20.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai==0.0.2) (1.64.1)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai==0.0.2) (1.64.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai==0.0.2) (1.26.4)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai==0.0.2) (2.10.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai==0.0.2) (2.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (3.7)\n",
      "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.9.1->mem0ai==0.0.2) (5.27.2)\n",
      "Requirement already satisfied: setuptools in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.9.1->mem0ai==0.0.2) (68.1.2)\n",
      "Requirement already satisfied: certifi in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (4.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from requests<3.0,>=2.7->posthog<4.0.0,>=3.5.0->mem0ai==0.0.2) (3.3.2)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from h2<5,>=3->httpx<1,>=0.23.0->openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /home/saleh-ahmad/Documents/Vector_Client_Work/Amal_Alshehri/env/lib/python3.11/site-packages (from h2<5,>=3->httpx<1,>=0.23.0->openai<2.0.0,>=1.33.0->mem0ai==0.0.2) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/SalehAhmad1/mem0.git@937d9b3f1bfffddcda86ea4a337608d0cd9372fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_url_existence(driver, url):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(1)\n",
    "        content_div = driver.find_element(By.CSS_SELECTOR, 'div.results') #if there are titles. that year has titles\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def extract_content(driver, title_url):\n",
    "    driver.get(title_url)\n",
    "    time.sleep(1)\n",
    "    Title_Content_Div = driver.find_element(By.CSS_SELECTOR, 'div.legToc')\n",
    "    NavBar = Title_Content_Div.find_element(By.ID, 'legSubNav')\n",
    "    NavBarLists = NavBar.find_elements(By.TAG_NAME, 'li')\n",
    "    ContentTab = NavBarLists[1]\n",
    "    Content_Link = ContentTab.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "    \n",
    "    driver.get(Content_Link)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    from embedchain.loaders.web_page import WebPageLoader\n",
    "    loader = WebPageLoader(tags_to_exclude=None, classes_to_exclude=None)\n",
    "    content = loader.load_data(Content_Link)\n",
    "    print(content['data'][0]['content'])\n",
    "    \n",
    "    #write to a txt and save\n",
    "    with open('content.txt', 'w') as f:\n",
    "        f.write(content['data'][0]['content'])\n",
    "    \n",
    "\n",
    "# '''Multiple Pages of the content page'''\n",
    "    # Page_Number = 1\n",
    "    # while True:\n",
    "    #     Content_Box = driver.find_element(By.ID, 'content')\n",
    "    #     Content_Text = Content_Box.find_element(By.ID, 'viewLegContents').find_element(By.CLASS_NAME, 'LegSnippet')\n",
    "    #     Content_Text_MiddleSection = Content_Text.find_element(By.CLASS_NAME, 'LegClearFix LegPrelims')\n",
    "        \n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseLoader.__init__() got an unexpected keyword argument 'tags_to_exclude'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39mChromeService(ChromeDriverManager()\u001b[38;5;241m.\u001b[39minstall()))\n\u001b[0;32m----> 2\u001b[0m \u001b[43mextract_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://www.legislation.gov.uk/ukpga/2024/22/contents/enacted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[72], line 24\u001b[0m, in \u001b[0;36mextract_content\u001b[0;34m(driver, title_url)\u001b[0m\n\u001b[1;32m     20\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01membedchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweb_page\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebPageLoader\n\u001b[0;32m---> 24\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mWebPageLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtags_to_exclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses_to_exclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m content \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_data(Content_Link)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(content[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseLoader.__init__() got an unexpected keyword argument 'tags_to_exclude'"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "extract_content(driver, 'https://www.legislation.gov.uk/ukpga/2024/22/contents/enacted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles_names_hrefs(driver, country, legislation_name, legislation_url):\n",
    "    All_Titles = {}\n",
    "\n",
    "    driver.get(legislation_url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    Target_Years = ['2024']\n",
    "    for idxYear, year in enumerate(Target_Years):\n",
    "        Target_Year_Legislation_URL = f'{legislation_url}/{year}'\n",
    "        check_target_year_existence = verify_url_existence(driver, Target_Year_Legislation_URL)\n",
    "            \n",
    "        if check_target_year_existence == False:\n",
    "            print(f'For the legislation: {legislation_name} does not have any titles for the year: {year}')\n",
    "        else:\n",
    "            Title_Names = []\n",
    "            Title_HREFs = []\n",
    "            num = 1\n",
    "            while True:\n",
    "                content_div = driver.find_element(By.CSS_SELECTOR, 'div.results')\n",
    "                table = content_div.find_element(By.TAG_NAME, 'table')\n",
    "                tbody = table.find_element(By.TAG_NAME, 'tbody')\n",
    "                tr_elements = tbody.find_elements(By.TAG_NAME, 'tr')\n",
    "                for tr in tr_elements: #Iterate over the table rows / titles\n",
    "                    first_td = tr.find_element(By.TAG_NAME, 'td')\n",
    "                    name = first_td.text\n",
    "                    href = first_td.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                    Title_Names.append(name)\n",
    "                    Title_HREFs.append(href)\n",
    "                    \n",
    "                footer = driver.find_element(By.CSS_SELECTOR, 'div.contentFooter')\n",
    "                ContentFooter = footer.find_element(By.CLASS_NAME, 'interface')\n",
    "                ContentFooterInterface = ContentFooter.find_element(By.CSS_SELECTOR, 'div.prevPagesNextNav')\n",
    "                List = ContentFooterInterface.find_element(By.TAG_NAME, 'ul')\n",
    "                Lists = List.find_elements(By.TAG_NAME, 'li')\n",
    "                \n",
    "                Next_Button_Found = False\n",
    "                LastButton = None\n",
    "                try:\n",
    "                    LastButton = Lists[-1].find_element(By.TAG_NAME, 'a')\n",
    "                    if 'Next' in LastButton.text:\n",
    "                        print(f'Next Button found: {LastButton.text}')\n",
    "                        Next_Button_Found = True\n",
    "                except:\n",
    "                    print(f'No Next Button Found - Last Page')\n",
    "                    All_Titles[year] = dict(zip(Title_Names, Title_HREFs))\n",
    "                    break\n",
    "                \n",
    "                if Next_Button_Found == True:\n",
    "                    num += 1\n",
    "                    print(f'Page: {num}')\n",
    "                    LastButton.click()\n",
    "                    time.sleep(2)\n",
    "    return All_Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idxCountry, (Country_Key, Country_Value_Dict) in enumerate(Final_Legislations.items()):\n",
    "    #print(f'Country_idx: {idxCountry} Country_Key: {Country_Key}') #, Country_Value_Dict: {Country_Value_Dict}\n",
    "    \n",
    "    for data_key, data_value in Country_Value_Dict.items(): #Iterates for 1 time. i.e. the only type of legislation in it\n",
    "        # print(f'\\tdata_key: {data_key}, data_value: {data_value}')\n",
    "        \n",
    "        for legislation_name, legislation_href in data_value.items():\n",
    "            '''Now that we have the target legislations, we need to get the titles for each country, each target year'''\n",
    "            print(f'{Country_Key} - {legislation_name}: {legislation_href}')\n",
    "            All_Titles = get_titles_names_hrefs(driver=driver, country=Country_Key, legislation_name=legislation_name, legislation_url=legislation_href)\n",
    "\n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "# Open the URL\n",
    "url = 'https://www.legislation.gov.uk/browse/uk'\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load completely\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "#gives us the two divs \n",
    "# Locate the div with the specified class using a more precise CSS selector\n",
    "div_element = driver.find_element(By.CSS_SELECTOR, 'div.s_4.p_one.legCol') \n",
    "\n",
    "# Locate the nested ul with the class 'legTypes' using a more general CSS selector within the entire document\n",
    "leg_types_elements = div_element.find_elements(By.CSS_SELECTOR, 'ul.legTypes')\n",
    "\n",
    "# Assuming there's only one such element\n",
    "if leg_types_elements:\n",
    "    leg_types_element = leg_types_elements[0]\n",
    "\n",
    "    # Locate the list items within the 'legTypes' ul\n",
    "    list_items = leg_types_element.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "    # Get the names (text content) of the list items\n",
    "    list_names = [item.text for item in list_items]\n",
    "\n",
    "    # Get the href attributes of the list items\n",
    "    list_hrefs = [item.find_element(By.TAG_NAME, 'a').get_attribute('href') for item in list_items if item.find_element(By.TAG_NAME, 'a')]\n",
    "\n",
    "    # Print the list names\n",
    "    print(\"List Names:\", list_names)\n",
    "\n",
    "    # Print the list hrefs\n",
    "    print(\"List Hrefs:\", list_hrefs)\n",
    "else:\n",
    "    print(\"No legTypes element found within the specified div.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for legislation_name, legislation_href in zip(list_names, list_hrefs):\n",
    "    print(f'{legislation_name}: {legislation_href}')\n",
    "    \n",
    "    driver.get(legislation_href)\n",
    "    \n",
    "    Target_Years = ['2024']\n",
    "    for idxYear,  year in enumerate(Target_Years):\n",
    "        try:\n",
    "            print(f'Year: {year}')\n",
    "\n",
    "            year_href = f'{legislation_href}/{year}'\n",
    "            driver.get(year_href)\n",
    "            \n",
    "            Page_Number = 1\n",
    "            '''Retrieve Titles for page 1'''\n",
    "            all_title_names = []\n",
    "            all_title_hrefs = []\n",
    "            content_div = driver.find_element(By.CSS_SELECTOR, 'div.results')\n",
    "            table = content_div.find_element(By.TAG_NAME, 'table')\n",
    "            tbody = table.find_element(By.TAG_NAME, 'tbody')\n",
    "            tr_elements = tbody.find_elements(By.TAG_NAME, 'tr')\n",
    "            for tr in tr_elements: #Iterate over the table rows / titles\n",
    "                first_td = tr.find_element(By.TAG_NAME, 'td')\n",
    "                name = first_td.text\n",
    "                href = first_td.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "\n",
    "            print(f'For the year: {year} we have: {len(all_title_names)} titles')\n",
    "        except:\n",
    "            print(f'The legislation:{legislation_name} does not have any titles for the year: {year}')\n",
    "        \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Initialize the Chrome driver\n",
    "# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "# # Base URL and target years\n",
    "# base_url = 'https://www.legislation.gov.uk/ukpga'\n",
    "# target_years = ['2024']\n",
    "\n",
    "# # List to store hrefs\n",
    "# all_hrefs = []\n",
    "\n",
    "# for year in target_years:\n",
    "#     # Construct the URL for the specific year\n",
    "#     url = f'{base_url}/{year}'#gives us the two divs\n",
    "#     print(f'Processing year {url}')\n",
    "#     driver.get(url)\n",
    "\n",
    "#     # Wait for the page to load completely\n",
    "#     driver.implicitly_wait(10)\n",
    "\n",
    "#     num = 1\n",
    "#     while True:\n",
    "#         try:\n",
    "#             # Locate the div with the class 'content'\n",
    "#             content_div = driver.find_element(By.CSS_SELECTOR, 'div.results')\n",
    "\n",
    "#             # Locate the table within the content div\n",
    "#             table = content_div.find_element(By.TAG_NAME, 'table')\n",
    "\n",
    "#             # Locate the tbody within the table\n",
    "#             tbody = table.find_element(By.TAG_NAME, 'tbody')\n",
    "\n",
    "#             # Locate all tr elements within the tbody\n",
    "#             tr_elements = tbody.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "#             for tr in tr_elements:\n",
    "#                 try:\n",
    "#                     # Get the first td element\n",
    "#                     first_td = tr.find_element(By.TAG_NAME, 'td')\n",
    "\n",
    "#                     # Find the 'a' tag within the first td and get its href\n",
    "#                     href = first_td.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                    \n",
    "#                     # Append the href to the list\n",
    "#                     all_hrefs.append(href)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing a row: {e}\")\n",
    "\n",
    "#             # Locate the pagination footer\n",
    "#             footer = driver.find_element(By.CSS_SELECTOR, 'div.contentFooter')\n",
    "#             ContentFooter = footer.find_element(By.CLASS_NAME, 'interface')\n",
    "#             ContentFooterInterface = ContentFooter.find_element(By.CSS_SELECTOR, 'div.prevPagesNextNav')\n",
    "#             List = ContentFooterInterface.find_element(By.TAG_NAME, 'ul')\n",
    "#             Lists = List.find_elements(By.TAG_NAME, 'li')\n",
    "#             NextButton = Lists[-1].find_element(By.TAG_NAME, 'a')\n",
    "            \n",
    "#             if NextButton and 'Next' in NextButton.text:\n",
    "#                 num += 1\n",
    "#                 print(f'Page: {num}')\n",
    "#                 NextButton.click()\n",
    "#                 time.sleep(2)\n",
    "#             else:\n",
    "#                 break\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing year {year}: {e}\")\n",
    "#             break\n",
    "\n",
    "# # Print all the collected hrefs\n",
    "# print(len(all_hrefs))\n",
    "# print(all_hrefs)\n",
    "\n",
    "# # Close the browser\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# # Initialize the Chrome driver\n",
    "# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "# # Open the URL\n",
    "# url = 'https://www.legislation.gov.uk/browse/uk'\n",
    "# driver.get(url)\n",
    "\n",
    "# # Locate the div with the specified class using a more precise CSS selector\n",
    "# div_element = driver.find_element(By.CSS_SELECTOR, 'div.s_4.p_two.legCol')\n",
    "\n",
    "# # Locate the nested ul with the class 'legTypes' using a more general CSS selector within the entire document\n",
    "# leg_types_elements = div_element.find_elements(By.CSS_SELECTOR, 'ul.legTypes')\n",
    "\n",
    "# # Assuming there's only one such element\n",
    "# if leg_types_elements:\n",
    "#     leg_types_element = leg_types_elements[0]\n",
    "\n",
    "#     # Locate the list items within the 'legTypes' ul\n",
    "#     list_items = leg_types_element.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "#     # Get the names (text content) of the list items\n",
    "#     list_names = [item.text for item in list_items]\n",
    "\n",
    "#     # Print the list names\n",
    "#     print(list_names)\n",
    "# else:\n",
    "#     print(\"No legTypes element found within the specified div.\")\n",
    "\n",
    "# # Close the browser\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
